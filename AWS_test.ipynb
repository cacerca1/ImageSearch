{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87aee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import seaborn as sn\n",
    "import boto3\n",
    "import re\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c259f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "_ = resnet50.eval()\n",
    "# _ = resnet50.cuda()\n",
    "\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9960def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return all s3 keys\n",
    "def get_all_s3_keys(bucket, filt=None):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"    \n",
    "    keys = []\n",
    "\n",
    "    kwargs = {'Bucket': bucket}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            if filt is not None:\n",
    "                if filt not in key:\n",
    "                    continue\n",
    "            keys.append('s3://' + bucket + '/' + key)\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ce4ba",
   "metadata": {},
   "source": [
    "# Test model with a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef329c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = 'sagemaker-us-east-2-333209439517'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uris = get_all_s3_keys(bucket, filt='jpg')\n",
    "\n",
    "s3_uris[0], len(s3_uris)\n",
    "\n",
    "s3_uri = s3_uris[0]\n",
    "\n",
    "s3_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uri = 's3://sagemaker-us-east-2-333209439517/geological_similarity/andesite/012L6.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = s3.get_object(Bucket=bucket,Key=s3_uri.replace(f's3://{bucket}/', ''))['Body'].read()\n",
    "\n",
    "im_file = BytesIO(payload)  # convert image to file-like object\n",
    "img = Image.open(im_file)   # img is now PIL Image object\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cf3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.asarray(img)# convert image to numpy array\n",
    "img = transform(im) # convert to tensor\n",
    "#img = img.reshape(1,3,28,28)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "img = img.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = resnet50(img)\n",
    "\n",
    "feature = feature.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17662e",
   "metadata": {},
   "source": [
    "# Save model to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c823a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1, 3, 28, 28]\n",
    "trace = torch.jit.trace(resnet50.float().eval(), torch.zeros(input_shape).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.save(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a10fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e18144",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job_name = name_from_base(\"TorchVision-ResNet50\")\n",
    "prefix = compilation_job_name + \"/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ba635",
   "metadata": {},
   "outputs": [],
   "source": [
    "compilation_job_name, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = sess.upload_data(path=\"model.tar.gz\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 's3://sagemaker-us-east-1-333209439517/TorchVision-ResNet50-2021-09-13-00-30-10-117/model/model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02ae5c",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77255b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    model_data=model_path,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMakerFullAccess - policy is a managed policy that includes all the necessary permissions required to perform most actions on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# set local_mode to False if you want to deploy on a remote\n",
    "# SageMaker instance\n",
    "\n",
    "local_mode = True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a48f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_image = base64.b64encode(payload).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb545df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bytes = base64.b64decode(encoded_image)   # im_bytes is a binary image\n",
    "im_file = BytesIO(im_bytes)  # convert image to file-like object\n",
    "image = Image.open(im_file)   # img is now PIL Image object\n",
    "im = np.asarray(image)# convert image to numpy array\n",
    "print(im.shape)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa17236",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = {'inputs':encoded_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = req\n",
    "initial_args=None\n",
    "target_model=None\n",
    "target_variant=None\n",
    "inference_id=None\n",
    "\n",
    "request_args = predictor._create_request_args(data, initial_args, target_model, target_variant, inference_id)\n",
    "response = predictor.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = predictor._handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(req)['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2795659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8392b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictor.predict(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e696f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0368f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04745913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddaf0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce9bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1a445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a function to extract image features\n",
    "from time import sleep \n",
    "\n",
    "sm_client = boto3.client('sagemaker-runtime')\n",
    "ENDPOINT_NAME = predictor.endpoint \n",
    "\n",
    "def get_predictions(payload): \n",
    "    return sm_client.invoke_endpoint(EndpointName=ENDPOINT_NAME, \n",
    "                                     ContentType='application/x-image', \n",
    "                                     Body=payload) \n",
    "\n",
    "def extract_features(s3_uri): \n",
    "    key = s3_uri.replace(f's3://{bucket}/', '') \n",
    "    payload = s3.get_object(Bucket=bucket,Key=key)['Body'].read() \n",
    "\n",
    "    sleep(0.1) \n",
    "    response = get_predictions(payload) \n",
    "        \n",
    "\n",
    "    response_body = json.loads((response['Body'].read())) \n",
    "    \n",
    "    feature_lst = response_body['predictions'][0] \n",
    "    \n",
    "    return s3_uri, feature_lst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Connect to Elasticsearch\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, service, session_token=credentials.token)\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "def create_index(index):\n",
    "    \"\"\"\n",
    "    This function will create an index using knn settings\n",
    "    \"\"\"\n",
    "    if not es.indices.exists(index=index):\n",
    "        index_settings = {\n",
    "            \"settings\": {\n",
    "                \"index.knn\": True,\n",
    "                \"index.mapping.total_fields.limit\": \"2000\"\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"embeddings\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 2048\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        es.indices.create(index=index, body=json.dumps(index_settings))\n",
    "        print(\"Created the elasticsearch index successufly \")\n",
    "    else:\n",
    "        print(\"elasticsearch index already exists\")\n",
    "\n",
    "\n",
    "#Create the index using knn settings\n",
    "create_index(es_index)\n",
    "\n",
    "\n",
    "# You can check if the index is created within your es cluster\n",
    "es.indices.get_alias(\"*\")\n",
    "\n",
    "def ingest_data_into_es(event):\n",
    "    \n",
    "    loaded_keys = []\n",
    "    \n",
    "    bucket = event['bucket']\n",
    "    key = event['key']\n",
    "\n",
    "    loaded_keys += [key]\n",
    "\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    records = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    lost_records = 0\n",
    "\n",
    "    for record in records:\n",
    "        # Get the primary key for use as the Elasticsearch ID\n",
    "        record_id = record['id']\n",
    "\n",
    "        try:\n",
    "            if 'embeddings' in record:\n",
    "                record['embeddings'] = ast.literal_eval(record['embeddings'])\n",
    "\n",
    "            es.index(index=es_index, id=record_id, doc_type='_doc', body=record)\n",
    "    \n",
    "            count += 1\n",
    "        except Exception as error:\n",
    "            logger.error(f\"An error {error} for record {record}\")\n",
    "            lost_records += 1\n",
    "\n",
    "        \n",
    "    logger.info(\n",
    "        f'{lost_records} out of {len(records)} are lost records')\n",
    "\n",
    "    logger.info(\n",
    "        f'{count} out of {len(records)} records has been processed')\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(str(count) + ' records processed.')\n",
    "    }\n",
    "\n",
    "\n",
    "#Check that data is indeed in ES\n",
    "res = es.search(index=es_index, body={\n",
    "                    \"query\": {\n",
    "                            \"match_all\": {}\n",
    "                        }},\n",
    "           size=10)\n",
    "\n",
    "\n",
    "\n",
    "es_query ={\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"embeddings\": {\n",
    "                        \"vector\": query_embeddings,\n",
    "                        \"k\": 5\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "\n",
    "res = es.search(index=es_index, body=es_query, size=page_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085ae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75788fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
