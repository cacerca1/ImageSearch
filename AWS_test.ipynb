{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ccded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import seaborn as sn\n",
    "import boto3\n",
    "import re\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c71fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/ec2-user/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a8713772f0445aa9a6f068d1254601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "_ = resnet50.eval()\n",
    "# _ = resnet50.cuda()\n",
    "\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50=nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725b4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return all s3 keys\n",
    "def get_all_s3_keys(bucket, filt=None):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"    \n",
    "    keys = []\n",
    "\n",
    "    kwargs = {'Bucket': bucket}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            if filt is not None:\n",
    "                if filt not in key:\n",
    "                    continue\n",
    "            keys.append('s3://' + bucket + '/' + key)\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ae6c3",
   "metadata": {},
   "source": [
    "# Test model with a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ba62a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-333209439517/geological_similarity/andesite/012L6.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = 'sagemaker-us-east-2-333209439517'\n",
    "\n",
    "s3_uris = get_all_s3_keys(bucket, filt='jpg')\n",
    "\n",
    "s3_uris[0], len(s3_uris)\n",
    "\n",
    "s3_uri = s3_uris[0]\n",
    "\n",
    "s3_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa666a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28 at 0x7F171CF57B00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = s3.get_object(Bucket=bucket,Key=s3_uri.replace(f's3://{bucket}/', ''))['Body'].read()\n",
    "\n",
    "\n",
    "\n",
    "im_file = BytesIO(payload)  # convert image to file-like object\n",
    "img = Image.open(im_file)   # img is now PIL Image object\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6614b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = np.asarray(img)# convert image to numpy array\n",
    "img = transform(im) # convert to tensor\n",
    "#img = img.reshape(1,3,28,28)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "img = img.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature = resnet50(img)\n",
    "\n",
    "feature = feature.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f42f0",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183ee365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4c508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80b4b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::333209439517:role/service-role/AmazonSageMaker-ExecutionRole-20210623T145063'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a308d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    model_data=pt_mnist_model_data,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# set local_mode to False if you want to deploy on a remote\n",
    "# SageMaker instance\n",
    "\n",
    "local_mode = True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictor.predict(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3467f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmodels\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mglob\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \n",
      "    \n",
      "    model = models.resnet50(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    _ = model.eval()\n",
      "\n",
      "    modules=\u001b[36mlist\u001b[39;49;00m(resnet50.children())[:-\u001b[34m1\u001b[39;49;00m]\n",
      "    model=nn.Sequential(*modules)\n",
      "    \u001b[34mfor\u001b[39;49;00m p \u001b[35min\u001b[39;49;00m model.parameters():\n",
      "        p.requires_grad = \u001b[34mFalse\u001b[39;49;00m\n",
      "\n",
      "    device = torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcuda:0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    model = model.to(device)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, request_content_type):\n",
      "    \u001b[34massert\u001b[39;49;00m request_content_type==\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    data = json.loads(request_body)[\u001b[33m'\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    data = torch.tensor(data, dtype=torch.float32, device=device)\n",
      "    \u001b[34mreturn\u001b[39;49;00m data\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        prediction = model(input_object)\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(predictions, content_type):\n",
      "    \u001b[34massert\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    res = predictions.cpu().numpy().tolist()\n",
      "    \u001b[34mreturn\u001b[39;49;00m json.dumps(res)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./code/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e249b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca488718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9de52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7392f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73401090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d97d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Deploy the model in Sagemaker Endpoint. This process will take ~10 min.\n",
    "from sagemaker.tensorflow.serving import Model \n",
    "\n",
    "sagemaker_model = Model(entry_point='inference.py', \n",
    "                        model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz', \n",
    "                        role = role, \n",
    "                        framework_version='2.1.0', \n",
    "                        source_dir='./src' ) \n",
    "predictor = sagemaker_model.deploy(initial_instance_count=3, \n",
    "                                   instance_type='ml.m5.xlarge')\n",
    "\n",
    "# define a function to extract image features\n",
    "from time import sleep \n",
    "\n",
    "sm_client = boto3.client('sagemaker-runtime')\n",
    "ENDPOINT_NAME = predictor.endpoint \n",
    "\n",
    "def get_predictions(payload): \n",
    "    return sm_client.invoke_endpoint(EndpointName=ENDPOINT_NAME, \n",
    "                                     ContentType='application/x-image', \n",
    "                                     Body=payload) \n",
    "\n",
    "def extract_features(s3_uri): \n",
    "    key = s3_uri.replace(f's3://{bucket}/', '') \n",
    "    payload = s3.get_object(Bucket=bucket,Key=key)['Body'].read() \n",
    "\n",
    "    sleep(0.1) \n",
    "    response = get_predictions(payload) \n",
    "        \n",
    "\n",
    "    response_body = json.loads((response['Body'].read())) \n",
    "    \n",
    "    feature_lst = response_body['predictions'][0] \n",
    "    \n",
    "    return s3_uri, feature_lst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Connect to Elasticsearch\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, service, session_token=credentials.token)\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "def create_index(index):\n",
    "    \"\"\"\n",
    "    This function will create an index using knn settings\n",
    "    \"\"\"\n",
    "    if not es.indices.exists(index=index):\n",
    "        index_settings = {\n",
    "            \"settings\": {\n",
    "                \"index.knn\": True,\n",
    "                \"index.mapping.total_fields.limit\": \"2000\"\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"embeddings\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 2048\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        es.indices.create(index=index, body=json.dumps(index_settings))\n",
    "        print(\"Created the elasticsearch index successufly \")\n",
    "    else:\n",
    "        print(\"elasticsearch index already exists\")\n",
    "\n",
    "\n",
    "#Create the index using knn settings\n",
    "create_index(es_index)\n",
    "\n",
    "\n",
    "# You can check if the index is created within your es cluster\n",
    "es.indices.get_alias(\"*\")\n",
    "\n",
    "def ingest_data_into_es(event):\n",
    "    \n",
    "    loaded_keys = []\n",
    "    \n",
    "    bucket = event['bucket']\n",
    "    key = event['key']\n",
    "\n",
    "    loaded_keys += [key]\n",
    "\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    records = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    lost_records = 0\n",
    "\n",
    "    for record in records:\n",
    "        # Get the primary key for use as the Elasticsearch ID\n",
    "        record_id = record['id']\n",
    "\n",
    "        try:\n",
    "            if 'embeddings' in record:\n",
    "                record['embeddings'] = ast.literal_eval(record['embeddings'])\n",
    "\n",
    "            es.index(index=es_index, id=record_id, doc_type='_doc', body=record)\n",
    "    \n",
    "            count += 1\n",
    "        except Exception as error:\n",
    "            logger.error(f\"An error {error} for record {record}\")\n",
    "            lost_records += 1\n",
    "\n",
    "        \n",
    "    logger.info(\n",
    "        f'{lost_records} out of {len(records)} are lost records')\n",
    "\n",
    "    logger.info(\n",
    "        f'{count} out of {len(records)} records has been processed')\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(str(count) + ' records processed.')\n",
    "    }\n",
    "\n",
    "\n",
    "#Check that data is indeed in ES\n",
    "res = es.search(index=es_index, body={\n",
    "                    \"query\": {\n",
    "                            \"match_all\": {}\n",
    "                        }},\n",
    "           size=10)\n",
    "\n",
    "\n",
    "\n",
    "es_query ={\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"embeddings\": {\n",
    "                        \"vector\": query_embeddings,\n",
    "                        \"k\": 5\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "\n",
    "res = es.search(index=es_index, body=es_query, size=page_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de2023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d5351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
