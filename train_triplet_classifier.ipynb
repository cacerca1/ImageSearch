{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for a similarity model using triplet loss.\n",
    "\n",
    "Babed on this tutorial: https://keras.io/examples/vision/siamese_network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 00:08:41.237082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:41.237112: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_shape = (28, 28)\n",
    "target_shape = (32,32)\n",
    "# target_shape = (56, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_triplets(anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )\n",
    "\n",
    "def visualize(anchor, positive, negative, num_samples=3):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 3*num_samples))\n",
    "\n",
    "    axs = fig.subplots(num_samples,3)\n",
    "    for i in range(num_samples):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/mnt/osn3/caceres/classes/geological/geological_similarity'\n",
    "\n",
    "classes = [ 'andesite', 'gneiss', 'marble', 'quartzite', 'rhyolite', 'schist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {}\n",
    "for i, label in enumerate(classes):\n",
    "    image_list = glob.glob(image_folder + '/' + label + '/*.jpg')\n",
    "    filenames[i] = []\n",
    "    for filename in image_list:\n",
    "        filenames[i].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000, 5000, 4998, 5000, 5000, 5000]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(v) for k,v in filenames.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = 0.2\n",
    "\n",
    "train_set = []\n",
    "test_set = []\n",
    "for k,v in filenames.items():\n",
    "    random.shuffle(v)\n",
    "    test_count = int(test_perc * len(v))\n",
    "    test_set.extend(v[:test_count])\n",
    "    train_set.extend(v[test_count:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23999, 5999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(image_list, batch_size=32):\n",
    "    \n",
    "    while True:\n",
    "        # choose random sample for batch\n",
    "        anchors = random.sample(image_list, batch_size)\n",
    "        #print(anchors)\n",
    "        positives = []\n",
    "        negatives = []\n",
    "        # get positive and negative\n",
    "        #c = 0\n",
    "        for anchor in anchors:\n",
    "            #print(c)\n",
    "            class_name, image_name = os.path.split(anchor)\n",
    "            _, class_name = os.path.split(class_name)\n",
    "    \n",
    "            failed = True\n",
    "            while failed:\n",
    "                positive = random.choice(image_list)\n",
    "                pos_class_name, pos_image_name = os.path.split(positive)\n",
    "                _, pos_class_name = os.path.split(pos_class_name)\n",
    "                #print('pos', class_name, image_name, pos_class_name, pos_image_name)\n",
    "                if class_name == pos_class_name and image_name != pos_image_name:\n",
    "                    failed = False\n",
    "            positives.append(positive)\n",
    "            \n",
    "            failed = True\n",
    "            while failed:\n",
    "                negative = random.choice(image_list)\n",
    "                neg_class_name, neg_image_name = os.path.split(negative)\n",
    "                _, neg_class_name = os.path.split(neg_class_name)\n",
    "                #print('neg', class_name, image_name, neg_class_name, neg_image_name)\n",
    "                if class_name != neg_class_name:\n",
    "                    failed = False\n",
    "            negatives.append(negative)\n",
    "            #c += 1\n",
    "            \n",
    "        tuple_triplets = [preprocess_triplets(anchor, pos, neg) for anchor, pos, neg in zip(anchors, positives, negatives)]\n",
    "\n",
    "        anchors, positives, negatives = zip(*tuple_triplets)\n",
    "        anchors = tensorflow.stack(anchors,0)\n",
    "        positives = tensorflow.stack(positives,0)\n",
    "        negatives = tensorflow.stack(negatives,0)\n",
    "        \n",
    "        dataset = [anchors, positives, negatives]\n",
    "        \n",
    "        #         print(anchors.shape)\n",
    "        #         print(positives.shape)\n",
    "        #         anchors = tf.data.Dataset.from_tensor_slices(anchors)\n",
    "        #         positives = tf.data.Dataset.from_tensor_slices(positives)\n",
    "        #         negatives = tf.data.Dataset.from_tensor_slices(negatives)\n",
    "\n",
    "        #         dataset = tf.data.Dataset.zip((anchors, positives, negatives))\n",
    "\n",
    "        #         dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "        #         dataset = dataset.prefetch(8)\n",
    "    \n",
    "        #print('yielding')\n",
    "        yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 00:08:43.098781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-17 00:08:43.099368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.099412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.099449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.101024: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.101069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.101105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-09-17 00:08:43.101114: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-17 00:08:43.101664: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "o = next(train_gen(test_set, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(*list(next(train_gen(test_set, batch_size=8))),num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(resnet.preprocess_input(anchor_input)),\n",
    "    embedding(resnet.preprocess_input(positive_input)),\n",
    "    embedding(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #print(type(inputs))\n",
    "        #print([x.shape for x in inputs]) #, len(inputs), inputs.shape)\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = len(train_set) // batch_size\n",
    "\n",
    "validation_steps = len(test_set) // batch_size\n",
    "\n",
    "steps_per_epoch,validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network, margin=10)\n",
    "siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n",
    "\n",
    "lr_steps_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=3, verbose=0,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "# siamese_model.fit(train_dataset, epochs=50, validation_data=val_dataset)\n",
    "\n",
    "history = siamese_model.fit(train_gen(train_set, batch_size=batch_size), \n",
    "                  epochs=50, \n",
    "                  validation_data=train_gen(test_set, batch_size=batch_size),\n",
    "                  steps_per_epoch=steps_per_epoch,\n",
    "                  validation_steps=validation_steps, \n",
    "                  callbacks=[lr_steps_callback, es_callback])\n",
    "\n",
    "# siamese_model.fit(input_fn(train_set, batch_size=32), \n",
    "#                   epochs=50, \n",
    "#                   validation_data=input_fn(test_set, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = next(iter(train_dataset))\n",
    "sample = next(train_gen(train_set, batch_size=batch_size))\n",
    "visualize(*sample)\n",
    "\n",
    "anchor, positive, negative = sample\n",
    "anchor_embedding, positive_embedding, negative_embedding = (\n",
    "    embedding(resnet.preprocess_input(anchor)),\n",
    "    embedding(resnet.preprocess_input(positive)),\n",
    "    embedding(resnet.preprocess_input(negative)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = metrics.CosineSimilarity()\n",
    "\n",
    "positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "print(\"Negative similarity\", negative_similarity.numpy())\n",
    "\n",
    "# Positive similarity: 0.99999315\n",
    "# Negative similarity 0.9999791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/ccaceresgarcia/Documents/Projects/image_search/ImageSearch/tripletExtractor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.saved_model.save(embedding, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.save('TripletResnet50_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(embedding(resnet.preprocess_input(anchor))[0,...].numpy().reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = anchor[0,...].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = []\n",
    "filenames = []\n",
    "features = []\n",
    "for i, label in enumerate(classes):\n",
    "    image_list = glob.glob(image_folder + '/' + label + '/*.jpg')\n",
    "\n",
    "    for filename in image_list:\n",
    "\n",
    "        img = preprocess_image(filename)\n",
    "        img = tensorflow.expand_dims(img, 0)\n",
    "        \n",
    "        feats = list(embedding(resnet.preprocess_input(img)).numpy().reshape(-1))\n",
    "        features.append(feats)\n",
    "        labels.append(label)\n",
    "        filenames.append(filename)\n",
    "        \n",
    "features2 = np.array(features)\n",
    "print(features2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write vectors to file for s3 upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = [str(list(x)) for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"resnet_triplet_vectors.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = {}\n",
    "for i, label in enumerate(classes):\n",
    "    label_features[i] = [(x, name) for name,x, la in zip(filenames, f3, labels) if la == label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for i, x in label_features.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Class files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(classes):\n",
    "    f4, lab_names = zip(*label_features[i])\n",
    "    \n",
    "    feature_data = {'labels':label, \n",
    "                'filenames':lab_names,\n",
    "                'features':f4}\n",
    "    \n",
    "    with open('resnet_triplet_vectors_{}.json'.format(label), 'w') as f:\n",
    "        json.dump(feature_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = {'labels':labels, \n",
    "                'filenames':filenames,\n",
    "                'features':f3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('resnet_triplet_vectors.json', 'w') as f:\n",
    "    json.dump(feature_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make KNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, label in enumerate(classes):\n",
    "#     image_list = glob.glob(image_folder + '/' + label + '/*.jpg')\n",
    "#     print(i,label, len(image_list))\n",
    "    \n",
    "# len(labels), len(filenames), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=30, algorithm='brute',metric='euclidean').fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # Its important to use binary mode \n",
    "# knnPickle = open('knnpickle_file', 'wb') \n",
    "\n",
    "# # source, destination \n",
    "# pickle.dump(neighbors, knnPickle)                      \n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open('knnpickle_file.pickle', 'rb'))\n",
    "\n",
    "# with open('filenames.pickle', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     pickle.dump(filenames, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filenames.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     loaded_filenames = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3\n",
    "# !pip3 install requests_aws4auth\n",
    "# !pip3 install elasticsearch=='7.13.4' #https://opensearch.org/docs/clients/index/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "\n",
    "for query in [random.randint(0,len(filenames)-1) for _ in range(10)]:\n",
    "    \n",
    "    img = preprocess_image(filenames[query])\n",
    "    img = tensorflow.expand_dims(img, 0)\n",
    "    flat_feature = list(embedding(resnet.preprocess_input(img)).numpy().reshape(-1))\n",
    "    distances, indices = neighbors.kneighbors([flat_feature])\n",
    "    \n",
    "    _, axes = plt.subplots(1,k,figsize=(16,4))\n",
    "    for i in range(k):\n",
    "        # load the image\n",
    "        match = indices[0][i]\n",
    "        image = Image.open(filenames[match])\n",
    "        # convert image to numpy array\n",
    "        im = np.asarray(image)\n",
    "        axes.flat[i].imshow(im)\n",
    "        axes.flat[i].set_title('{}-{} \\n {}-{}-{:.3f}'.format(query, \n",
    "                                                              labels[query], \n",
    "                                                              match, \n",
    "                                                              labels[match], \n",
    "                                                              round(distances[0][i],3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(x):\n",
    "    return os.path.split(os.path.split(x)[0])[1]\n",
    "\n",
    "get_class(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features(filename):\n",
    "    img = preprocess_image(filename)\n",
    "    img = tensorflow.expand_dims(img, 0)\n",
    "    flat_feature = list(embedding(resnet.preprocess_input(img)).numpy().reshape(-1))\n",
    "    return flat_feature\n",
    "\n",
    "def calculate_accuracy(model_func, filenames, k=5):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(filenames)):\n",
    "\n",
    "        flat_feature = model_func(filenames[i])\n",
    "        distances, indices = neighbors.kneighbors([flat_feature])\n",
    "        #print(len(indices[0]))\n",
    "        for j in range(k):\n",
    "            if get_class(filenames[indices[0][j]]) == get_class(filenames[i]):\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "                \n",
    "    return correct/(correct+incorrect)\n",
    "\n",
    "for k in range(1,20):\n",
    "    ts = time.time()\n",
    "    acc = calculate_accuracy(get_features, filenames, k) \n",
    "    print(k, ':', acc, 'took: ', time.time() - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,20):\n",
    "    ts = time.time()\n",
    "    acc = calculate_accuracy(get_features, filenames, k) \n",
    "    print(k, ':', acc, 'took: ', time.time() - ts)\n",
    "\n",
    "# 1 : 1.0 took:  3362.8139638900757\n",
    "# 2 : 0.9531468764584305 took:  3293.8385870456696\n",
    "# 3 : 0.9357290486032402 took:  3257.395818710327\n",
    "# 4 : 0.9269367957863858 took:  3337.58216547966\n",
    "# 5 : 0.9213880925395026 took:  3263.669928789139\n",
    "# 6 : 0.917550058892815 took:  3321.3202335834503\n",
    "# 7 : 0.9145133485089482 took:  3265.5803034305573\n",
    "# 8 : 0.9123941596106407 took:  3340.8867971897125\n",
    "# 9 : 0.910668118615315 took:  3289.156872034073\n",
    "# 10 : 0.9092439495966398 took:  3318.057454586029\n",
    "# 11 : 0.9080847814096698 took:  3267.5558347702026\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
